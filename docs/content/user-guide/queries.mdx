---
title: Creating Queries
description: Learn how to create and execute queries against agents and teams
---

# Creating Queries

Queries are how you interact with models, tools, agents and teams in ARK. A query sends input to any target, or set of targets, and receives a response. You can create queries using `kubectl`, the `fark` CLI, the ARK APIs or our OpenAI-compatible endpoints.

## What is a Query?

A query is a request to execute a task using an agent or team. It contains:

- **Input**: The prompt or question you want to ask
- **Target**: Which agent or team should process the request
- **Output**: The response from the agent or team

Queries support [overrides](/user-guide/overrides) to dynamically inject headers when interacting with models and MCP servers.

### User Messages

If a `type` is not specified, then the input of a query is a single user message:

```yaml
apiVersion: ark.mckinsey.com/v1alpha1
kind: Query
metadata:
  name: query-simple
spec:
  input: "What is the capital of France"
  target:
    type: agent
    name: sample-agent
```

Apply this sample query with:

```bash
# Create the 'sample agent' if you haven't already, then run the query.
kubectl apply -f samples/agents/sample-agent.yaml
kubectl apply -f samples/queries/query-simple.yaml
```

Check the result:

```bash
kubectl get query query-simple -o yaml
```

### Structured Conversations

The `messages` query type can be used to input a structured conversation (messages array):

```yaml
apiVersion: ark.mckinsey.com/v1alpha1
kind: Query
metadata:
  name: conversation-messages
  namespace: default
spec:
  type: messages
  input:
    - role: user
      content: "Calculate 1+1."
    - role: assistant
      content: "2"
    - role: user
      content: "Calculate 2+2."
    - role: assistant
      content: "4"
    - role: user
      content: "What is the sum of all previous sums?"
  target:
    type: agent
    name: sample-agent
```

Apply this query using kubectl:

```bash
# Create the 'sample agent' if you haven't already, then run the query.
kubectl apply -f samples/agents/sample-agent.yaml
kubectl apply -f samples/queries/query-conversation-messages.yaml
```

Check the result:

```bash
kubectl get query conversation-messages -o yaml
```

The `messages` input type allows you to build up conversation context, by adding the response of each query into an OpenAI message object array.

Notes:

- `type` is optional; if omitted, it defaults to `user` (string input).
- For `type: messages`, `input` must be an array of objects with `role` and `content` fields.
- Supported roles: `user`, `assistant`, `system`, and provider-specific roles.

## Using ark CLI

The ark CLI provides an interactive query interface with streaming responses:

```bash
# Query an agent
ark query agent/weather-agent "What's the weather like in New York?"

# Query a model directly
ark query model/gpt-4 "Explain kubernetes operators"

# Query a team
ark query team/research-team "Analyze this data"
```

### Options

```bash
# Set a custom timeout
ark query agent/my-agent "Long running task" --timeout 10m

# Enable automatic retries (useful for rate limits)
ark query agent/my-agent "Process this" --max-retries 3

# Track queries with session ID for telemetry
ark query agent/my-agent "Hello" --session-id user-123

# Output as YAML/JSON instead of streaming
ark query agent/my-agent "Hello" -o yaml
```

## Using fark CLI

Query an agent directly:

```bash
fark agent weather-agent "What's the weather like in New York?"
```

Query a team:

```bash
fark team team-seq "Analyze this data and provide recommendations"
```

Create a named query:

```bash
fark query my-query
```

## Using OpenAI-Compatible Endpoints

The OpenAI-compatible API lets you use familiar tools and libraries to interact with your agents and teams.

Explore the [Ark APIs](/reference/ark-apis) docs to see how to run the APIs in detail.

### List Available Targets

You can use the [OpenAI List Models API](https://platform.openai.com/docs/api-reference/models/list) to show all available query targets. This will show things like `tool/get_weater`, `model/claude-4-opus`, `agent/weather-reporter`, or `team/coding-team`.

See all available agents, teams, models, and tools:

```bash
curl http://ark-api.default.127.0.0.1.nip.io:8080/openai/v1/models
```

### Query a Agent

Query a model, agent, team or tool using the exact same syntax that you would use to query an LLM with the OpenAI SDK:

```bash
curl -X POST http://ark-api.default.127.0.0.1.nip.io:8080/openai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "agent/weather-agent",
    "messages": [
      {"role": "user", "content": "What'\''s the weather like in New York?"}
    ]
  }'
```

Response:

```json
{
  "id": "query-abc123",
  "object": "chat.completion",
  "model": "agent/weather-agent",
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "The current weather in New York is 72°F with partly cloudy skies..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 12,
    "completion_tokens": 25,
    "total_tokens": 37
  }
}
```

### Using the OpenAI SDK

As the ARK APIs offer OpenAI compatible APIs, you can use any OpenAI SDK to issue queries:

```python
from openai import OpenAI

client = OpenAI(
    api_key="not-needed",
    base_url="http://ark-api.default.127.0.0.1.nip.io:8080/openai/v1"
)

response = client.chat.completions.create(
    model="agent/github-repo-accessor",
    messages=[
        {"role": "user", "content": "Find repositories about kubernetes"}
    ]
)

print(response.choices[0].message.content)
```

### Query a Team

```bash
curl -X POST http://ark-api.default.127.0.0.1.nip.io:8080/openai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "team/team-seq",
    "messages": [
      {"role": "user", "content": "Analyze customer feedback and suggest improvements"}
    ]
  }'
```

Response:
```json
{
  "id": "query-def456",
  "object": "chat.completion", 
  "model": "team/team-seq",
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "Based on the customer feedback analysis:\n1. Product quality is highly rated\n2. Shipping speed needs improvement\n3. Customer service response time should be reduced..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 18,
    "completion_tokens": 45,
    "total_tokens": 63
  }
}
```

## Advanced

### Query Retry Policies

Configure automatic retries for transient failures like rate limits or network timeouts. Add a `retryPolicy` to your Query spec:

```yaml
apiVersion: ark.mckinsey.com/v1alpha1
kind: Query
metadata:
  name: resilient-query
spec:
  input: "Analyze this data"
  target:
    type: agent
    name: data-analyst
  retryPolicy:
    maxRetries: 3           # Retry up to 3 times (0-10)
    backoffPolicy: exponential  # exponential, linear, or fixed
    initialDelay: 1s        # Wait 1s before first retry
    maxDelay: 30s           # Cap delay at 30s
```

**Backoff policies:**
- `exponential` (default): Delay doubles each retry (1s → 2s → 4s...), capped at `maxDelay`
- `linear`: Delay increases by `initialDelay` each retry (1s → 2s → 3s...)
- `fixed`: Constant delay of `initialDelay` between all retries

Monitor retry attempts:

```bash
# Check retry count for a query
kubectl get query my-query -o jsonpath='{.status.retryCount}'

# List queries with retry column
kubectl get queries
```

See the [Query Reference](/reference/resources/query#retry-policy) for complete retry policy documentation.

## Next Steps

- Explore the [Ark APIs](/reference/ark-apis) for complete endpoint documentation
- Learn about [Tools and MCP Servers](/user-guide/tools) to extend agent capabilities
- Check out [Tips on Building Agentic Use Cases](/user-guide/tips-on-building-agentic-use-cases) for best practices
