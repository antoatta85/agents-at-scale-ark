apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ml-training-pipeline
  namespace: default
  annotations:
    workflows.argoproj.io/title: "ML Model Training & Deployment Pipeline"
    workflows.argoproj.io/description: "End-to-end machine learning pipeline that ingests data from multiple sources, performs parallel feature engineering, trains multiple models concurrently, evaluates their performance, selects the best model, and deploys it to staging and production environments with comprehensive validation and monitoring"
spec:
  entrypoint: main-pipeline
  arguments:
    parameters:
    - name: dataset-version
      value: "v1.2.0"
    - name: model-types
      value: "random-forest,xgboost,neural-network"
    - name: training-epochs
      value: "100"
    - name: batch-size
      value: "32"

  volumeClaimTemplates:
  - metadata:
      name: workspace
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 50Gi

  templates:
  - name: main-pipeline
    steps:
    - - name: init-workspace
        template: initialize-workspace

    - - name: validate-config
        template: validate-configuration
        arguments:
          parameters:
          - name: dataset-version
            value: "{{workflow.parameters.dataset-version}}"

    - - name: data-ingestion-us
        template: ingest-data
        arguments:
          parameters:
          - name: region
            value: "us-east-1"
          - name: source
            value: "s3://data-lake/us/"
      - name: data-ingestion-eu
        template: ingest-data
        arguments:
          parameters:
          - name: region
            value: "eu-west-1"
          - name: source
            value: "s3://data-lake/eu/"
      - name: data-ingestion-asia
        template: ingest-data
        arguments:
          parameters:
          - name: region
            value: "ap-southeast-1"
          - name: source
            value: "s3://data-lake/asia/"

    - - name: merge-datasets
        template: merge-data
        arguments:
          artifacts:
          - name: us-data
            from: "{{steps.data-ingestion-us.outputs.artifacts.processed-data}}"
          - name: eu-data
            from: "{{steps.data-ingestion-eu.outputs.artifacts.processed-data}}"
          - name: asia-data
            from: "{{steps.data-ingestion-asia.outputs.artifacts.processed-data}}"

    - - name: data-quality-check
        template: validate-data-quality
        arguments:
          artifacts:
          - name: merged-data
            from: "{{steps.merge-datasets.outputs.artifacts.merged-dataset}}"

    - - name: feature-engineering-numeric
        template: engineer-numeric-features
        arguments:
          artifacts:
          - name: dataset
            from: "{{steps.merge-datasets.outputs.artifacts.merged-dataset}}"
      - name: feature-engineering-categorical
        template: engineer-categorical-features
        arguments:
          artifacts:
          - name: dataset
            from: "{{steps.merge-datasets.outputs.artifacts.merged-dataset}}"
      - name: feature-engineering-temporal
        template: engineer-temporal-features
        arguments:
          artifacts:
          - name: dataset
            from: "{{steps.merge-datasets.outputs.artifacts.merged-dataset}}"
      - name: feature-engineering-text
        template: engineer-text-features
        arguments:
          artifacts:
          - name: dataset
            from: "{{steps.merge-datasets.outputs.artifacts.merged-dataset}}"

    - - name: combine-features
        template: combine-feature-sets
        arguments:
          artifacts:
          - name: numeric-features
            from: "{{steps.feature-engineering-numeric.outputs.artifacts.features}}"
          - name: categorical-features
            from: "{{steps.feature-engineering-categorical.outputs.artifacts.features}}"
          - name: temporal-features
            from: "{{steps.feature-engineering-temporal.outputs.artifacts.features}}"
          - name: text-features
            from: "{{steps.feature-engineering-text.outputs.artifacts.features}}"

    - - name: split-dataset
        template: train-test-split
        arguments:
          artifacts:
          - name: full-dataset
            from: "{{steps.combine-features.outputs.artifacts.feature-dataset}}"

    - - name: train-random-forest
        template: train-model
        arguments:
          parameters:
          - name: model-type
            value: "random-forest"
          - name: epochs
            value: "{{workflow.parameters.training-epochs}}"
          artifacts:
          - name: train-data
            from: "{{steps.split-dataset.outputs.artifacts.train-set}}"
      - name: train-xgboost
        template: train-model
        arguments:
          parameters:
          - name: model-type
            value: "xgboost"
          - name: epochs
            value: "{{workflow.parameters.training-epochs}}"
          artifacts:
          - name: train-data
            from: "{{steps.split-dataset.outputs.artifacts.train-set}}"
      - name: train-neural-network
        template: train-model
        arguments:
          parameters:
          - name: model-type
            value: "neural-network"
          - name: epochs
            value: "{{workflow.parameters.training-epochs}}"
          artifacts:
          - name: train-data
            from: "{{steps.split-dataset.outputs.artifacts.train-set}}"
      - name: train-gradient-boosting
        template: train-model
        arguments:
          parameters:
          - name: model-type
            value: "gradient-boosting"
          - name: epochs
            value: "{{workflow.parameters.training-epochs}}"
          artifacts:
          - name: train-data
            from: "{{steps.split-dataset.outputs.artifacts.train-set}}"

    - - name: evaluate-random-forest
        template: evaluate-model
        arguments:
          parameters:
          - name: model-type
            value: "random-forest"
          artifacts:
          - name: model
            from: "{{steps.train-random-forest.outputs.artifacts.trained-model}}"
          - name: test-data
            from: "{{steps.split-dataset.outputs.artifacts.test-set}}"
      - name: evaluate-xgboost
        template: evaluate-model
        arguments:
          parameters:
          - name: model-type
            value: "xgboost"
          artifacts:
          - name: model
            from: "{{steps.train-xgboost.outputs.artifacts.trained-model}}"
          - name: test-data
            from: "{{steps.split-dataset.outputs.artifacts.test-set}}"
      - name: evaluate-neural-network
        template: evaluate-model
        arguments:
          parameters:
          - name: model-type
            value: "neural-network"
          artifacts:
          - name: model
            from: "{{steps.train-neural-network.outputs.artifacts.trained-model}}"
          - name: test-data
            from: "{{steps.split-dataset.outputs.artifacts.test-set}}"
      - name: evaluate-gradient-boosting
        template: evaluate-model
        arguments:
          parameters:
          - name: model-type
            value: "gradient-boosting"
          artifacts:
          - name: model
            from: "{{steps.train-gradient-boosting.outputs.artifacts.trained-model}}"
          - name: test-data
            from: "{{steps.split-dataset.outputs.artifacts.test-set}}"

    - - name: compare-models
        template: model-comparison
        arguments:
          artifacts:
          - name: rf-metrics
            from: "{{steps.evaluate-random-forest.outputs.artifacts.metrics}}"
          - name: xgb-metrics
            from: "{{steps.evaluate-xgboost.outputs.artifacts.metrics}}"
          - name: nn-metrics
            from: "{{steps.evaluate-neural-network.outputs.artifacts.metrics}}"
          - name: gb-metrics
            from: "{{steps.evaluate-gradient-boosting.outputs.artifacts.metrics}}"

    - - name: select-best-model
        template: select-champion-model
        arguments:
          artifacts:
          - name: comparison-report
            from: "{{steps.compare-models.outputs.artifacts.report}}"

    - - name: model-explainability
        template: generate-explanations
        arguments:
          parameters:
          - name: champion-model
            value: "{{steps.select-best-model.outputs.parameters.best-model}}"
      - name: bias-fairness-check
        template: check-model-fairness
        arguments:
          parameters:
          - name: champion-model
            value: "{{steps.select-best-model.outputs.parameters.best-model}}"
      - name: adversarial-testing
        template: adversarial-robustness-test
        arguments:
          parameters:
          - name: champion-model
            value: "{{steps.select-best-model.outputs.parameters.best-model}}"

    - - name: package-model
        template: create-deployment-package
        arguments:
          parameters:
          - name: champion-model
            value: "{{steps.select-best-model.outputs.parameters.best-model}}"
          - name: version
            value: "{{workflow.parameters.dataset-version}}"

    - - name: deploy-staging
        template: deploy-to-environment
        arguments:
          parameters:
          - name: environment
            value: "staging"
          - name: model-version
            value: "{{workflow.parameters.dataset-version}}"
          artifacts:
          - name: package
            from: "{{steps.package-model.outputs.artifacts.deployment-package}}"

    - - name: staging-smoke-tests
        template: run-smoke-tests
        arguments:
          parameters:
          - name: environment
            value: "staging"
      - name: staging-integration-tests
        template: run-integration-tests
        arguments:
          parameters:
          - name: environment
            value: "staging"
      - name: staging-load-tests
        template: run-load-tests
        arguments:
          parameters:
          - name: environment
            value: "staging"

    - - name: canary-deployment
        template: deploy-canary
        arguments:
          parameters:
          - name: traffic-percentage
            value: "10"
          artifacts:
          - name: package
            from: "{{steps.package-model.outputs.artifacts.deployment-package}}"

    - - name: monitor-canary-metrics
        template: monitor-deployment
        arguments:
          parameters:
          - name: duration-minutes
            value: "30"
          - name: deployment-type
            value: "canary"

    - - name: promote-to-production
        template: deploy-to-environment
        arguments:
          parameters:
          - name: environment
            value: "production"
          - name: model-version
            value: "{{workflow.parameters.dataset-version}}"
          artifacts:
          - name: package
            from: "{{steps.package-model.outputs.artifacts.deployment-package}}"
        when: "{{steps.monitor-canary-metrics.outputs.parameters.health-status}} == healthy"

    - - name: production-validation
        template: validate-production
        arguments:
          parameters:
          - name: model-version
            value: "{{workflow.parameters.dataset-version}}"

    - - name: update-model-registry
        template: register-model
        arguments:
          parameters:
          - name: model-id
            value: "{{steps.select-best-model.outputs.parameters.best-model}}"
          - name: version
            value: "{{workflow.parameters.dataset-version}}"
          - name: status
            value: "production"
      - name: generate-documentation
        template: create-model-documentation
        arguments:
          parameters:
          - name: model-id
            value: "{{steps.select-best-model.outputs.parameters.best-model}}"
      - name: notify-stakeholders
        template: send-notifications
        arguments:
          parameters:
          - name: deployment-status
            value: "success"
          - name: model-version
            value: "{{workflow.parameters.dataset-version}}"

  - name: initialize-workspace
    container:
      image: alpine:latest
      command: [sh, -c]
      args: ["echo Initializing workspace && mkdir -p /workspace/{data,models,artifacts} && sleep 2"]
      volumeMounts:
      - name: workspace
        mountPath: /workspace

  - name: validate-configuration
    inputs:
      parameters:
      - name: dataset-version
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        version = "{{inputs.parameters.dataset-version}}"
        print(f"Validating configuration for dataset version {version}")
        print("Configuration valid")

  - name: ingest-data
    inputs:
      parameters:
      - name: region
      - name: source
    outputs:
      artifacts:
      - name: processed-data
        path: /tmp/data-{{inputs.parameters.region}}.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        region = "{{inputs.parameters.region}}"
        source = "{{inputs.parameters.source}}"
        print(f"Ingesting data from {source} in region {region}")
        time.sleep(5)
        data = {"region": region, "records": 10000, "source": source}
        with open('/tmp/data-{{inputs.parameters.region}}.json', 'w') as f:
          json.dump(data, f)
        print(f"Ingested {data['records']} records")
      resources:
        requests:
          memory: "512Mi"
          cpu: "500m"

  - name: merge-data
    inputs:
      artifacts:
      - name: us-data
        path: /tmp/us-data.json
      - name: eu-data
        path: /tmp/eu-data.json
      - name: asia-data
        path: /tmp/asia-data.json
    outputs:
      artifacts:
      - name: merged-dataset
        path: /tmp/merged-dataset.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        print("Merging regional datasets")
        time.sleep(3)
        merged = {"total_records": 30000, "regions": ["us", "eu", "asia"]}
        with open('/tmp/merged-dataset.json', 'w') as f:
          json.dump(merged, f)
        print("Datasets merged successfully")

  - name: validate-data-quality
    inputs:
      artifacts:
      - name: merged-data
        path: /tmp/merged-data.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import time
        print("Running data quality checks")
        time.sleep(4)
        print("✓ No missing values")
        print("✓ Data types validated")
        print("✓ Distribution checks passed")
        print("Data quality: PASSED")

  - name: engineer-numeric-features
    inputs:
      artifacts:
      - name: dataset
        path: /tmp/dataset.json
    outputs:
      artifacts:
      - name: features
        path: /tmp/numeric-features.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        print("Engineering numeric features: scaling, normalization, polynomial")
        time.sleep(6)
        features = {"type": "numeric", "count": 45}
        with open('/tmp/numeric-features.json', 'w') as f:
          json.dump(features, f)

  - name: engineer-categorical-features
    inputs:
      artifacts:
      - name: dataset
        path: /tmp/dataset.json
    outputs:
      artifacts:
      - name: features
        path: /tmp/categorical-features.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        print("Engineering categorical features: encoding, embedding")
        time.sleep(5)
        features = {"type": "categorical", "count": 23}
        with open('/tmp/categorical-features.json', 'w') as f:
          json.dump(features, f)

  - name: engineer-temporal-features
    inputs:
      artifacts:
      - name: dataset
        path: /tmp/dataset.json
    outputs:
      artifacts:
      - name: features
        path: /tmp/temporal-features.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        print("Engineering temporal features: seasonality, trends, lags")
        time.sleep(5)
        features = {"type": "temporal", "count": 18}
        with open('/tmp/temporal-features.json', 'w') as f:
          json.dump(features, f)

  - name: engineer-text-features
    inputs:
      artifacts:
      - name: dataset
        path: /tmp/dataset.json
    outputs:
      artifacts:
      - name: features
        path: /tmp/text-features.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        print("Engineering text features: TF-IDF, embeddings, sentiment")
        time.sleep(7)
        features = {"type": "text", "count": 512}
        with open('/tmp/text-features.json', 'w') as f:
          json.dump(features, f)

  - name: combine-feature-sets
    inputs:
      artifacts:
      - name: numeric-features
        path: /tmp/numeric.json
      - name: categorical-features
        path: /tmp/categorical.json
      - name: temporal-features
        path: /tmp/temporal.json
      - name: text-features
        path: /tmp/text.json
    outputs:
      artifacts:
      - name: feature-dataset
        path: /tmp/features.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        print("Combining all feature sets")
        time.sleep(3)
        combined = {"total_features": 598}
        with open('/tmp/features.json', 'w') as f:
          json.dump(combined, f)

  - name: train-test-split
    inputs:
      artifacts:
      - name: full-dataset
        path: /tmp/dataset.json
    outputs:
      artifacts:
      - name: train-set
        path: /tmp/train.json
      - name: test-set
        path: /tmp/test.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        print("Splitting dataset: 80% train, 20% test")
        time.sleep(2)
        with open('/tmp/train.json', 'w') as f:
          json.dump({"samples": 24000}, f)
        with open('/tmp/test.json', 'w') as f:
          json.dump({"samples": 6000}, f)

  - name: train-model
    inputs:
      parameters:
      - name: model-type
      - name: epochs
      artifacts:
      - name: train-data
        path: /tmp/train.json
    outputs:
      artifacts:
      - name: trained-model
        path: /tmp/model.pkl
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        model_type = "{{inputs.parameters.model-type}}"
        epochs = "{{inputs.parameters.epochs}}"
        print(f"Training {model_type} model for {epochs} epochs")
        time.sleep(15)
        model = {"type": model_type, "epochs": epochs, "trained": True}
        with open('/tmp/model.pkl', 'w') as f:
          json.dump(model, f)
        print(f"Training complete for {model_type}")
      resources:
        requests:
          memory: "2Gi"
          cpu: "2000m"
        limits:
          memory: "4Gi"
          cpu: "4000m"

  - name: evaluate-model
    inputs:
      parameters:
      - name: model-type
      artifacts:
      - name: model
        path: /tmp/model.pkl
      - name: test-data
        path: /tmp/test.json
    outputs:
      artifacts:
      - name: metrics
        path: /tmp/metrics.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        import random
        model_type = "{{inputs.parameters.model-type}}"
        print(f"Evaluating {model_type} model")
        time.sleep(5)
        metrics = {
          "model": model_type,
          "accuracy": round(0.85 + random.random() * 0.1, 4),
          "precision": round(0.83 + random.random() * 0.1, 4),
          "recall": round(0.82 + random.random() * 0.1, 4),
          "f1_score": round(0.84 + random.random() * 0.1, 4)
        }
        with open('/tmp/metrics.json', 'w') as f:
          json.dump(metrics, f)
        print(f"Metrics: {metrics}")

  - name: model-comparison
    inputs:
      artifacts:
      - name: rf-metrics
        path: /tmp/rf-metrics.json
      - name: xgb-metrics
        path: /tmp/xgb-metrics.json
      - name: nn-metrics
        path: /tmp/nn-metrics.json
      - name: gb-metrics
        path: /tmp/gb-metrics.json
    outputs:
      artifacts:
      - name: report
        path: /tmp/comparison-report.json
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        import time
        print("Comparing model performances")
        time.sleep(3)
        report = {"best_model": "xgboost", "comparison": "complete"}
        with open('/tmp/comparison-report.json', 'w') as f:
          json.dump(report, f)

  - name: select-champion-model
    inputs:
      artifacts:
      - name: comparison-report
        path: /tmp/report.json
    outputs:
      parameters:
      - name: best-model
        valueFrom:
          path: /tmp/champion.txt
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import json
        with open('/tmp/report.json') as f:
          report = json.load(f)
        champion = report['best_model']
        print(f"Champion model selected: {champion}")
        with open('/tmp/champion.txt', 'w') as f:
          f.write(champion)

  - name: generate-explanations
    inputs:
      parameters:
      - name: champion-model
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args: ["echo Generating SHAP values and feature importance for {{inputs.parameters.champion-model}} && sleep 4"]

  - name: check-model-fairness
    inputs:
      parameters:
      - name: champion-model
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args: ["echo Checking bias and fairness metrics for {{inputs.parameters.champion-model}} && sleep 3"]

  - name: adversarial-robustness-test
    inputs:
      parameters:
      - name: champion-model
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args: ["echo Running adversarial robustness tests for {{inputs.parameters.champion-model}} && sleep 4"]

  - name: create-deployment-package
    inputs:
      parameters:
      - name: champion-model
      - name: version
    outputs:
      artifacts:
      - name: deployment-package
        path: /tmp/package.tar.gz
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args:
      - |
        echo "Creating deployment package for {{inputs.parameters.champion-model}} v{{inputs.parameters.version}}"
        sleep 3
        echo "package-data" > /tmp/package.tar.gz

  - name: deploy-to-environment
    inputs:
      parameters:
      - name: environment
      - name: model-version
      artifacts:
      - name: package
        path: /tmp/package.tar.gz
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args: ["echo Deploying model v{{inputs.parameters.model-version}} to {{inputs.parameters.environment}} && sleep 5 && echo Deployment complete"]

  - name: run-smoke-tests
    inputs:
      parameters:
      - name: environment
    container:
      image: curlimages/curl:latest
      command: [sh, -c]
      args: ["echo Running smoke tests in {{inputs.parameters.environment}} && sleep 3 && echo Smoke tests: PASSED"]

  - name: run-integration-tests
    inputs:
      parameters:
      - name: environment
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args: ["echo Running integration tests in {{inputs.parameters.environment}} && sleep 4 && echo Integration tests: PASSED"]

  - name: run-load-tests
    inputs:
      parameters:
      - name: environment
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args: ["echo Running load tests in {{inputs.parameters.environment}} && sleep 6 && echo Load tests: PASSED"]

  - name: deploy-canary
    inputs:
      parameters:
      - name: traffic-percentage
      artifacts:
      - name: package
        path: /tmp/package.tar.gz
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args: ["echo Deploying canary with {{inputs.parameters.traffic-percentage}}% traffic && sleep 4"]

  - name: monitor-deployment
    inputs:
      parameters:
      - name: duration-minutes
      - name: deployment-type
    outputs:
      parameters:
      - name: health-status
        valueFrom:
          path: /tmp/health.txt
    container:
      image: python:3.11-slim
      command: [python, -c]
      args:
      - |
        import time
        duration = {{inputs.parameters.duration-minutes}}
        deployment_type = "{{inputs.parameters.deployment-type}}"
        print(f"Monitoring {deployment_type} deployment for {duration} minutes")
        time.sleep(8)
        print("Error rate: 0.1%")
        print("Latency p99: 120ms")
        print("Resource usage: Normal")
        with open('/tmp/health.txt', 'w') as f:
          f.write('healthy')

  - name: validate-production
    inputs:
      parameters:
      - name: model-version
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args: ["echo Validating production deployment v{{inputs.parameters.model-version}} && sleep 3 && echo Validation: SUCCESS"]

  - name: register-model
    inputs:
      parameters:
      - name: model-id
      - name: version
      - name: status
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args: ["echo Registering model {{inputs.parameters.model-id}} v{{inputs.parameters.version}} with status {{inputs.parameters.status}} && sleep 2"]

  - name: create-model-documentation
    inputs:
      parameters:
      - name: model-id
    container:
      image: python:3.11-slim
      command: [sh, -c]
      args: ["echo Generating documentation for model {{inputs.parameters.model-id}} && sleep 3"]

  - name: send-notifications
    inputs:
      parameters:
      - name: deployment-status
      - name: model-version
    container:
      image: curlimages/curl:latest
      command: [sh, -c]
      args:
      - |
        echo "Sending notifications"
        echo "Status: {{inputs.parameters.deployment-status}}"
        echo "Version: {{inputs.parameters.model-version}}"
        sleep 2
